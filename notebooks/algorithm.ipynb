{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e452d2c",
   "metadata": {},
   "source": [
    "## Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184470c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a19e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_colwidth', None)  # Disable truncation of column contents\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Router\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d07b3e",
   "metadata": {},
   "source": [
    "## Loading edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4312d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_edges = spark.read.orc('/group/grande_envergure/graph/complete_edges.orc')\n",
    "df_all_edges= complete_edges.toPandas()\n",
    "df_all_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):\n",
    "    \"\"\"Get seconds from time.\n",
    "\n",
    "    Args:\n",
    "        time_str: A string representing time in the format \"HH:MM:SS\".\n",
    "\n",
    "    Returns:\n",
    "        seconds: The total number of seconds represented by the input time.\n",
    "    \"\"\"\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def get_time(seconds):\n",
    "    \"\"\"Get time from seconds.\n",
    "\n",
    "    Args:\n",
    "        seconds: An integer representing the total number of seconds.\n",
    "\n",
    "    Returns:\n",
    "        time_str: A string representing the time in the format \"HH:MM:SS\".\n",
    "    \"\"\"\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%02d:%02d:%02d\" % (h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dedd3",
   "metadata": {},
   "source": [
    "Transforming the times into seconds and keeping only valid edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_edges[\"start_time\"]=df_all_edges[\"start_time\"].apply(lambda x: None if x is None else get_sec(x))\n",
    "df_all_edges[\"end_time\"]=df_all_edges[\"end_time\"].apply(lambda x: None if x is None else get_sec(x))\n",
    "df_all_edges= df_all_edges[~df_all_edges[\"expected_travel_time\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907b9be",
   "metadata": {},
   "source": [
    "## Loading nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_zurich = spark.read.orc('/group/grande_envergure/graph/nodes_zurich.orc')\n",
    "nodes_zurich= nodes_zurich.toPandas()\n",
    "nodes_zurich.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f5272",
   "metadata": {},
   "source": [
    "# Finding the best Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca9353",
   "metadata": {},
   "source": [
    "First let us define some usefull functions to find the best paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path_info(path_graph):\n",
    "    \"\"\"Compute the infos about the points for the shortest paths in the graph.\n",
    "    Args:\n",
    "        path_graph: A NetworkX DiGraph instance.\n",
    "    Returns:\n",
    "        paths_info: A list of lists of dictionaries containing information about each point in the paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate all shortest paths\n",
    "    all_shortest_paths = nx.all_shortest_paths(path_graph, \"start\", \"end\", weight=\"expected_travel_time\")\n",
    "\n",
    "    # Get the first 20 paths\n",
    "    first_20_shortest_paths = list(itertools.islice(all_shortest_paths, 20))\n",
    "    # Initialise the infos array \n",
    "    paths_info = []\n",
    "    \n",
    "    # Traverse each path\n",
    "    for path in first_20_shortest_paths:\n",
    "        path_info = []\n",
    "        # Traverse the nodes in the path\n",
    "        for node in path[1:-1]:\n",
    "            # Add edges infos \n",
    "            src_departure_time = path_graph.nodes[node][\"start_time\"]\n",
    "            dst_arrival_time = path_graph.nodes[node][\"end_time\"]\n",
    "            src = path_graph.nodes[node][\"start_stop_id\"]\n",
    "            dst = path_graph.nodes[node][\"end_stop_id\"]\n",
    "            trip = path_graph.nodes[node][\"trip_id\"]\n",
    "            edge = {\"start_time\":get_time(src_departure_time), \n",
    "                 \"end_time\":get_time(dst_arrival_time), \n",
    "                 \"start_stop_id\":src, \n",
    "                 \"end_stop_id\":dst, \n",
    "                 \"trip_id\":trip}\n",
    "            path_info.append(edge)\n",
    "        \n",
    "        paths_info.append(path_info)\n",
    "\n",
    "    return paths_info\n",
    "\n",
    "def add_node_to_graph(graph, index, row):\n",
    "    \"\"\"Add a node to the given graph.\n",
    "\n",
    "    Args:\n",
    "        graph (networkx.DiGraph): The graph to which the node will be added.\n",
    "        index (int): The identifier for the node.\n",
    "        row (pandas.Series): The row of data containing node attributes.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    graph.add_node(\n",
    "        index, \n",
    "        start_stop_id=row['start_stop_id'], \n",
    "        end_stop_id=row['end_stop_id'], \n",
    "        start_time=row['start_time'], \n",
    "        end_time=row['end_time'], \n",
    "        expected_travel_time=row['expected_travel_time'],\n",
    "        trip_id=row['trip_id']\n",
    "    )\n",
    "\n",
    "def add_walking_nodes_to_graph(path_graph, start, end, extracted, edges, row, i):\n",
    "    \"\"\"Add walking nodes to the given graph.\n",
    "\n",
    "    Args:\n",
    "        path_graph (networkx.DiGraph): The graph to which the nodes will be added.\n",
    "        start (str): The identifier for the start node.\n",
    "        end (str): The identifier for the end node.\n",
    "        extracted (list): The extracted nodes.\n",
    "        edges (pandas.DataFrame): The dataframe containing the edge information.\n",
    "        row (pandas.Series): The row of data containing node attributes.\n",
    "        i (int): The incremental index for the node.\n",
    "\n",
    "    Returns:\n",
    "        i (int): The updated incremental index for the node.\n",
    "    \"\"\"\n",
    "    if start == extracted[0][0]:\n",
    "        connections_next = edges[(edges[\"start_stop_id\"]==end) & (edges[\"is_walking\"]==0)]\n",
    "        for index_next, row_next in connections_next.iterrows():\n",
    "            walk_time = row[\"expected_travel_time\"]\n",
    "            walk_time_end = row_next[\"start_time\"]\n",
    "            walk_time_start = walk_time_end - walk_time\n",
    "            node_attributes = {\n",
    "                \"start_time\": walk_time_start,\n",
    "                \"end_time\": walk_time_end,\n",
    "                \"expected_travel_time\": walk_time,\n",
    "                \"start_stop_id\": row[\"start_stop_id\"],\n",
    "                \"end_stop_id\": row[\"end_stop_id\"],\n",
    "                \"trip_id\": \"None\"\n",
    "            }\n",
    "            path_graph.add_node(index_next + i, **node_attributes)\n",
    "            i += 1\n",
    "    else:\n",
    "        connections_prev = [(node, attr) for node, attr in path_graph.nodes(data=True) if attr[\"end_stop_id\"]==row[\"start_stop_id\"]]\n",
    "        for prev_node, prev_attr in connections_prev:\n",
    "            walk_time = row[\"expected_travel_time\"]\n",
    "            walk_time_start = prev_attr[\"end_time\"]\n",
    "            walk_time_end = walk_time_start + walk_time\n",
    "            node_attributes = {\n",
    "                \"start_time\": walk_time_start,\n",
    "                \"end_time\": walk_time_end,\n",
    "                \"expected_travel_time\": walk_time,\n",
    "                \"start_stop_id\": row[\"start_stop_id\"],\n",
    "                \"end_stop_id\": row[\"end_stop_id\"],\n",
    "                \"trip_id\": \"None\"\n",
    "            }\n",
    "            path_graph.add_node(prev_node + i, **node_attributes)\n",
    "            i += 1\n",
    "\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(extracted, edges):\n",
    "    \"\"\"Given a dataframe of edges and pairs of nodes return feasable \n",
    "\n",
    "    Args:\n",
    "        extracted: ordered pairs of nodes representing the desired edges\n",
    "        edges: all available edges in the graph\n",
    "\n",
    "    Returns:\n",
    "        paths: All feasable paths with the same node tuple sequence as in extracted\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new directed graph\n",
    "    path_graph= nx.DiGraph()\n",
    "\n",
    "    # Iterate through all extracted paths\n",
    "    for start,end in extracted:\n",
    "        # Get all edges starting from the current node\n",
    "        connections = edges[edges[\"start_stop_id\"]==start]\n",
    "        # Initialize an arbitrary large number\n",
    "        i=1000000000\n",
    "\n",
    "        # Iterate through all connections\n",
    "        for index,row in connections.iterrows(): \n",
    "            # If the connection is not a walking path\n",
    "            if row['is_walking']==0 :\n",
    "                # Add the connection as a node to the graph\n",
    "                add_node_to_graph(path_graph, index, row)\n",
    "            else:\n",
    "                # Add walking nodes to the graph\n",
    "                i = add_walking_nodes_to_graph(path_graph, start, end, extracted, edges, row, i)\n",
    "\n",
    "\n",
    "    # Iterate over all nodes in the graph\n",
    "    for node_1_i, node_1 in path_graph.nodes(data=True):\n",
    "        for node_2_i, node_2  in path_graph.nodes(data=True):\n",
    "            # Skip if it's the same node\n",
    "            if node_1_i == node_2_i:\n",
    "                continue\n",
    "            # If the end of the first node is the start of the second, and they are close in time\n",
    "            if (node_1['end_stop_id']==node_2['start_stop_id'] and ((node_1['end_time']<= node_2['start_time'])or (abs(node_1['end_time'] - node_2['start_time']) <10) )):\n",
    "                # Add a directed edge from the first node to the second with the travel time as the weight\n",
    "                path_graph.add_edge(node_1_i, node_2_i, expected_travel_time= (node_2['start_time'] - node_1['start_time']))\n",
    "\n",
    "    #This allows the route to start from any time \n",
    "    # Get all nodes that start from the first stop in the extracted path\n",
    "    connections_from_start = [(node,attr) for node, attr in path_graph.nodes(data=True) if attr[\"start_stop_id\"]==extracted[0][0]]\n",
    "    # If no such nodes exist, return None\n",
    "    if len(connections_from_start) == 0:\n",
    "        return \n",
    "    # For all nodes that start from the first stop, add an edge from a \"start\" node to them with weight 0\n",
    "    for node,attr in connections_from_start:\n",
    "        path_graph.add_edge(\"start\",node,expected_travel_time=0)\n",
    "    \n",
    "    # Get all nodes that end at the final stop in the extracted path\n",
    "    connections_to_dest = [(node,attr) for node, attr in path_graph.nodes(data=True) if node!=\"start\" and attr[\"end_stop_id\"]==extracted[-1][1]]\n",
    "    # If no such nodes exist, return None\n",
    "    if len(connections_to_dest) == 0:\n",
    "        return \n",
    "    # For all nodes that end at the final stop, add an edge from them to an \"end\" node with their expected travel time as the weight\n",
    "    for node,attr in connections_to_dest:\n",
    "        path_graph.add_edge(node,\"end\",expected_travel_time=attr[\"expected_travel_time\"])\n",
    "\n",
    "    # If there's a path from the \"start\" node to the \"end\" node\n",
    "    if nx.has_path(path_graph,\"start\",\"end\"):\n",
    "        # Return the path with additional info added\n",
    "        return add_path_info(path_graph)  \n",
    "    else: \n",
    "        # If there's no path, return None\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_total_time(data_list):\n",
    "    \"\"\"Calculate the total time between the start and end of a path\n",
    "\n",
    "    Args:\n",
    "        data_list: A list of dictionaries representing the path.\n",
    "\n",
    "    Returns:\n",
    "        total_time: The total time in seconds between the start and end\n",
    "                    of the path.\n",
    "    \"\"\"\n",
    "    time_format = '%H:%M:%S'\n",
    "\n",
    "    # Convert the start time and end time to datetime objects\n",
    "    start_time = datetime.strptime(data_list[0]['start_time'], time_format)\n",
    "    end_time = datetime.strptime(data_list[-1]['end_time'], time_format)\n",
    "\n",
    "    # Calculate the total time in seconds\n",
    "    total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b02503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_k_fastest(paths, k):\n",
    "    \"\"\"Select the k fastest paths in a list\n",
    "\n",
    "    Args:\n",
    "        paths: list of list of dictionnary representing edges\n",
    "        k: number of paths to keep\n",
    "\n",
    "    Returns:\n",
    "        shortest_paths: The k shortest paths\n",
    "    \"\"\"\n",
    "    #Compute the time for each path\n",
    "    paths_with_time = [(calculate_total_time(path), path) for path in paths]\n",
    "    # Sort paths based on total time\n",
    "    paths_with_time.sort(key=lambda x: x[0])  \n",
    "    # Select the k shortest paths\n",
    "    shortest_paths = paths_with_time[:k]  \n",
    "    # Return only paths, without their total time\n",
    "    shortest_paths = [path for total_time, path in shortest_paths]\n",
    "\n",
    "    return shortest_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9682d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplucate_paths (paths):\n",
    "    \"\"\"Select the k fastest paths in a list\n",
    "\n",
    "    Args:\n",
    "        paths: list of list of dictionnary representing edges\n",
    "        \n",
    "    Returns:\n",
    "        unique_paths: list of unique paths\n",
    "        \n",
    "    \"\"\"\n",
    "    unique_paths_dict = {}\n",
    "    \n",
    "    # A path is considered unique if it has a unique start time and end time\n",
    "    for path in paths:\n",
    "        start_time = path[0]['start_time']\n",
    "        end_time = path[-1]['end_time']\n",
    "        unique_paths_dict[(start_time, end_time)] = path\n",
    "\n",
    "    # Get the unique paths from the dictionary\n",
    "    unique_paths = list(unique_paths_dict.values())\n",
    "    return unique_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e97e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_trips(trip_data):\n",
    "    \"\"\"Compresses a path so that each edge represents a unique \n",
    "        transportation mean\n",
    "\n",
    "    Args:\n",
    "        trip_data: list of dictionnary representing edges\n",
    "        \n",
    "    Returns:\n",
    "        compressed_trips: A list of dictionnary where edges are compressed by trip_id\n",
    "        \n",
    "    \"\"\"\n",
    "    compressed_trips = []\n",
    "    for trip in trip_data:\n",
    "        # If the trip can not be compressed \n",
    "        if not compressed_trips or trip['trip_id'] != compressed_trips[-1]['trip_id'] or (trip['trip_id'] is None and compressed_trips[-1]['trip_id'] is None):\n",
    "            compressed_trips.append(trip.copy())\n",
    "        # If the trip can be compressed \n",
    "        else:\n",
    "            compressed_trips[-1]['end_time'] = trip['end_time']\n",
    "            compressed_trips[-1]['end_stop_id'] = trip['end_stop_id']\n",
    "    return compressed_trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704315ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_paths(df_all_edges, source, sink, desired_arrival_time, max_trip_length, k):\n",
    "    \n",
    "    desired_arrival_time = get_sec(desired_arrival_time)\n",
    "    # Filter the edges data frame based on whether the end time is within the range of the desired arrival time \n",
    "    # and the maximum trip length.\n",
    "    df_all_edges = df_all_edges[(df_all_edges[\"is_walking\"]==1) |  ((df_all_edges[\"end_time\"] <= desired_arrival_time) & (df_all_edges[\"end_time\"]>desired_arrival_time-max_trip_length))]\n",
    "    \n",
    "    # Create a directed graph using the filtered edges data frame.\n",
    "    graph = nx.from_pandas_edgelist(df_all_edges, 'start_stop_id', 'end_stop_id', edge_attr=['expected_travel_time'],create_using=nx.DiGraph)\n",
    "    \n",
    "    # Generate a list of fastest paths (with a limit of 100) from the source to the sink node based on the expected travel time.\n",
    "    fastest_paths = list(islice(nx.shortest_simple_paths(graph, source, sink, weight='expected_travel_time'), 100))\n",
    "    \n",
    "    result = []\n",
    "    # For each path, zip together start and end stop IDs, create a data frame with these pairs and merge it with the filtered edges data frame.\n",
    "    for path in fastest_paths:\n",
    "        extracted = list(zip(path[:-1], path[1:]))\n",
    "        df_pairs = pd.DataFrame(extracted, columns=[\"start_stop_id\",\"end_stop_id\"])\n",
    "        df_edges_filtered = df_all_edges.merge(df_pairs, on=[\"start_stop_id\",\"end_stop_id\"], how=\"inner\")\n",
    "        \n",
    "        # Get the path if it exists and append it to the result list.\n",
    "        if get_path(extracted, df_edges_filtered):\n",
    "            i = 0\n",
    "            for p in get_path(extracted, df_edges_filtered):\n",
    "                if i < 20:  # The maximum number of paths to be stored for each extracted path.\n",
    "                    result.append(p)\n",
    "                    i = i + 1\n",
    "                    \n",
    "    # Filter out the None values from the result list.\n",
    "    paths= [r for r in result if r != None]\n",
    "    \n",
    "    # Drop duplicate paths and compress trips in each unique path.\n",
    "    unique_paths = drop_duplucate_paths(paths)\n",
    "    compressed_paths = [compress_trips(trip) for trip in unique_paths]\n",
    "    \n",
    "    # Get the fastest k paths from the compressed paths.\n",
    "    fastest_k_paths = keep_k_fastest(compressed_paths, k)\n",
    "    \n",
    "    return fastest_k_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8367c",
   "metadata": {},
   "source": [
    "# Delay Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03aceed-a765-4518-ae34-d4604a4bfbac",
   "metadata": {},
   "source": [
    "We can now make use of our previous work for delay estimation. <br>\n",
    "We start by importing df_mean which contains the average delay for each stop at each hour.\n",
    "This will be really usefull in order to estimate the delays with exponential low!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the table from hdfs\n",
    "isdt = spark.read.orc('/group/grande_envergure/graph/isdt_delay_mean.orc')\n",
    "\n",
    "#transform it to a pandas df\n",
    "df_mean = isdt.toPandas()\n",
    "df_mean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dd3e4-3c48-4a94-acb6-b9ece551f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "isdt_delay = spark.read.orc('/group/grande_envergure/graph/isdt_delay.orc')\n",
    "isdt_delay.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab52bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nbimporter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921404f-c5a3-44c4-b37b-f61da2084ea1",
   "metadata": {},
   "source": [
    "Then we import all methods from probabilistic_delay notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import probabilistic_delay "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01ec89",
   "metadata": {},
   "source": [
    "# Grphical Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14616127",
   "metadata": {},
   "source": [
    "We start by adding Widgets for parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b70bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "number_routes = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Number of Paths',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "max_trip_length = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=3,\n",
    "    step=1,\n",
    "    description='Max trip duration (H)',\n",
    "    style=style\n",
    ")\n",
    "hours = widgets.BoundedFloatText(min=0, max=23, value=12, step=1, description='Hour')\n",
    "minutes = widgets.BoundedFloatText(min=0, max=59, value=0, step=1, description='Minute')\n",
    "validate_butt = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Show validation',\n",
    "    style=style,\n",
    "    tooltip='Description',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "stop_names = sorted(nodes_zurich['stop_name'].unique())\n",
    "\n",
    "start = widgets.Dropdown(options=stop_names, description='From:')\n",
    "start.value ='Egg'\n",
    "\n",
    "end = widgets.Dropdown(options=stop_names, description='To:')\n",
    "end.value = 'ZÃ¼rich Flughafen'\n",
    "\n",
    "button = widgets.Button(description=\"Run query\")\n",
    "data_output = widgets.Output()\n",
    "map_output = widgets.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63351c",
   "metadata": {},
   "source": [
    "We then define methods to handle display of paths as dataframes and maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(df):\n",
    "    # Extract start and end stops into separate dataframes\n",
    "    start_stops = df[['start_stop_name', 'start_lat', 'start_lon']]\n",
    "    end_stops = df[['end_stop_name', 'end_lat', 'end_lon']]\n",
    "\n",
    "    # Rename columns to uniform names\n",
    "    start_stops.columns = ['stop_name', 'stop_lat', 'stop_lon']\n",
    "    end_stops.columns = ['stop_name', 'stop_lat', 'stop_lon']\n",
    "\n",
    "    # Concatenate the start and end dataframes into a single dataframe\n",
    "    map_df = pd.concat([start_stops, end_stops])\n",
    "\n",
    "    fig = go.Figure()  # Initialize the figure\n",
    "\n",
    "    # add the lines\n",
    "    for _, row in df.iterrows():\n",
    "        fig.add_trace(\n",
    "            go.Scattermapbox(\n",
    "                mode = \"lines\",\n",
    "                lon = [row['start_lon'], row['end_lon']],\n",
    "                lat = [row['start_lat'], row['end_lat']],\n",
    "                marker = {'size': 10},\n",
    "                hoverinfo = 'none', ))\n",
    "\n",
    "    # Add the nodes after the lines\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lat=map_df[\"stop_lat\"],\n",
    "            lon=map_df[\"stop_lon\"],\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color='red'),  # changed color to red\n",
    "            text=map_df[\"stop_name\"],\n",
    "            hoverinfo='text'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        hovermode='closest',\n",
    "        mapbox=dict(\n",
    "            bearing=0,\n",
    "            center=dict(\n",
    "                lat=47.3769, \n",
    "                lon=8.5417\n",
    "            ),\n",
    "            pitch=0,\n",
    "            zoom=10\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def print_data(df):\n",
    "    data_output.clear_output()\n",
    "    with data_output :\n",
    "        display(df)\n",
    "    \n",
    "def print_map(df):\n",
    "    map_output.clear_output()\n",
    "    with map_output :\n",
    "        display(create_map(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de45973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function triggered when a button is clicked\n",
    "def on_button_clicked(btn):\n",
    "    \n",
    "    # Retrieve all the parameters from the widget values\n",
    "    k = int(number_routes.value)\n",
    "    source = start.value\n",
    "    source = nodes_zurich[nodes_zurich['stop_name']== source]['stop_id'].values[0]\n",
    "    sink = end.value\n",
    "    sink = nodes_zurich[nodes_zurich['stop_name']== sink]['stop_id'].values[0]\n",
    "    time = str(int(hours.value)).zfill(2) + \":\"+ str(int(minutes.value)).zfill(2) + \":00\" \n",
    "    max_length = int(max_trip_length.value)\n",
    "    validate = validate_butt.value\n",
    "    \n",
    "    # Call the function to get the top k paths with provided parameters\n",
    "    paths = get_k_paths(df_all_edges= df_all_edges, source=source,sink=sink,desired_arrival_time= time,max_trip_length=max_length * 60 * 60 ,k=k)\n",
    "    paths.sort(key = lambda path: path[0][\"start_time\"], reverse=True)\n",
    "    \n",
    "    paths_proba = [probabilistic_delay.trip_conf(path,df_mean) for path in paths]\n",
    "    if validate:\n",
    "        paths_validate=[probabilistic_delay.trip_val(path,isdt_delay) for path in paths]\n",
    "    # Convert each path into a pandas DataFrame and store them into a list\n",
    "    dfs = [pd.DataFrame(path) for path in paths]\n",
    "    \n",
    "\n",
    "    # Create a tab widget for displaying the DataFrame of each path\n",
    "    tab = widgets.Tab()\n",
    "    data_output_tabs = [widgets.Output() for _ in dfs]\n",
    "    tab.children = data_output_tabs\n",
    "\n",
    "    # Create a tab widget for displaying the map of each path\n",
    "    map_tab = widgets.Tab()\n",
    "    map_output_tabs = [widgets.Output() for _ in dfs]\n",
    "    map_tab.children = map_output_tabs\n",
    "    \n",
    "    # Check if the list is not empty\n",
    "    if dfs:  \n",
    "        for i, df in enumerate(dfs):\n",
    "            # Set title for each tab\n",
    "            tab.set_title(i, f'Path {i + 1}')\n",
    "            # Fill in extra information about stations \n",
    "            df['start_stop_name'] = df.apply(lambda row: nodes_zurich[nodes_zurich['stop_id'] == row['start_stop_id']]['stop_name'].values[0], axis=1)\n",
    "            df['end_stop_name'] = df.apply(lambda row: nodes_zurich[nodes_zurich['stop_id'] == row['end_stop_id']]['stop_name'].values[0], axis=1)\n",
    "            df['walking'] = df.apply(lambda row: row['trip_id'] == 'None', axis=1)\n",
    "            df['start_lat'] = df['start_stop_id'].apply(lambda id: nodes_zurich[nodes_zurich['stop_id'] == id]['stop_lat'].values[0])\n",
    "            df['start_lon'] = df['start_stop_id'].apply(lambda id: nodes_zurich[nodes_zurich['stop_id'] == id]['stop_lon'].values[0])\n",
    "            df['end_lat'] = df['end_stop_id'].apply(lambda id: nodes_zurich[nodes_zurich['stop_id'] == id]['stop_lat'].values[0])\n",
    "            df['end_lon'] = df['end_stop_id'].apply(lambda id: nodes_zurich[nodes_zurich['stop_id'] == id]['stop_lon'].values[0])\n",
    "            \n",
    "           # Create greeting label and a DataFrame widget\n",
    "            if validate :\n",
    "                greeting = widgets.Label(f'The probability to be able to achieve path {i + 1} is {int(paths_proba[i]*100)}% and {int(paths_validate[i]*100)}% of identical paths succeeded in historical data')\n",
    "            else :\n",
    "                greeting = widgets.Label(f'The probability to be able to achieve path {i + 1} is {int(paths_proba[i]*100)}%')\n",
    "            # Display VBox in corresponding output widget\n",
    "            with data_output_tabs[i]:\n",
    "                data_output_tabs[i].clear_output()\n",
    "                display(greeting)  # Display greeting label\n",
    "                display(df[['start_stop_name', 'end_stop_name', 'start_time', 'end_time', 'walking']])\n",
    "            \n",
    "            # Set title for each map tab\n",
    "            map_tab.set_title(i, f'Map {i + 1}')\n",
    "            \n",
    "            # Display map in corresponding output widget\n",
    "            with map_output_tabs[i]:   \n",
    "                map_output_tabs[i].clear_output()\n",
    "                display(create_map(df))\n",
    "\n",
    "        # Clear old outputs and display the tab widget in data_output widget\n",
    "        with data_output:\n",
    "            data_output.clear_output()\n",
    "            display(tab)\n",
    "        \n",
    "        # Clear old outputs and display the tab widget in map_output widget\n",
    "        with map_output:\n",
    "            map_output.clear_output()\n",
    "            display(map_tab)\n",
    "    else:\n",
    "        # If no paths, print an empty DataFrame and an empty map\n",
    "        print_data(pd.DataFrame())  \n",
    "        print_map(pd.DataFrame()) \n",
    "        \n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc73d31",
   "metadata": {},
   "source": [
    "Finally, we display all the widgets together "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa976277-0e4e-445e-be43-a61c35818951",
   "metadata": {},
   "source": [
    "# Normal querries take around 15 seconds but reaches 2 min if validation is activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82697579",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_widgets = widgets.HBox([hours, minutes, number_routes,validate_butt])\n",
    "nodes_widgets = widgets.HBox([start, end, max_trip_length])\n",
    "\n",
    "all_widgets = widgets.VBox([input_widgets, nodes_widgets, button])\n",
    "\n",
    "tab = widgets.Tab([data_output, map_output])\n",
    "tab.set_title(0, 'Planning')\n",
    "tab.set_title(1, 'Map')\n",
    "\n",
    "dashboard = widgets.VBox([all_widgets, tab])\n",
    "display(dashboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
